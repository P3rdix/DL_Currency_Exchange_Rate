{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e36a0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 18:46:05.615843: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-25 18:46:05.617460: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-25 18:46:05.651203: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-25 18:46:05.651665: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-25 18:46:06.384734: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    LayerNormalization,\n",
    "    MultiHeadAttention,\n",
    "    Flatten,\n",
    "    Add,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    mean_squared_error,\n",
    ")\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a649d955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Australia</th>\n",
       "      <th>Europe</th>\n",
       "      <th>Brazil</th>\n",
       "      <th>Canada</th>\n",
       "      <th>China</th>\n",
       "      <th>Denmark</th>\n",
       "      <th>Hong Kong</th>\n",
       "      <th>India</th>\n",
       "      <th>Japan</th>\n",
       "      <th>Malaysia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.9133</td>\n",
       "      <td>1.4419</td>\n",
       "      <td>1.7200</td>\n",
       "      <td>1.0377</td>\n",
       "      <td>6.8273</td>\n",
       "      <td>5.1597</td>\n",
       "      <td>7.7555</td>\n",
       "      <td>46.27</td>\n",
       "      <td>92.55</td>\n",
       "      <td>3.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>0.9143</td>\n",
       "      <td>1.4402</td>\n",
       "      <td>1.7296</td>\n",
       "      <td>1.0371</td>\n",
       "      <td>6.8258</td>\n",
       "      <td>5.1668</td>\n",
       "      <td>7.7564</td>\n",
       "      <td>46.13</td>\n",
       "      <td>91.48</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>0.9189</td>\n",
       "      <td>1.4404</td>\n",
       "      <td>1.7292</td>\n",
       "      <td>1.0333</td>\n",
       "      <td>6.8272</td>\n",
       "      <td>5.1638</td>\n",
       "      <td>7.7546</td>\n",
       "      <td>45.72</td>\n",
       "      <td>92.53</td>\n",
       "      <td>3.379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>0.9168</td>\n",
       "      <td>1.4314</td>\n",
       "      <td>1.7409</td>\n",
       "      <td>1.0351</td>\n",
       "      <td>6.8280</td>\n",
       "      <td>5.1981</td>\n",
       "      <td>7.7539</td>\n",
       "      <td>45.67</td>\n",
       "      <td>93.31</td>\n",
       "      <td>3.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>0.9218</td>\n",
       "      <td>1.4357</td>\n",
       "      <td>1.7342</td>\n",
       "      <td>1.0345</td>\n",
       "      <td>6.8274</td>\n",
       "      <td>5.1827</td>\n",
       "      <td>7.7553</td>\n",
       "      <td>45.50</td>\n",
       "      <td>92.70</td>\n",
       "      <td>3.375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  Australia  Europe  Brazil  Canada   China  \\\n",
       "0             0  2010-01-04     0.9133  1.4419  1.7200  1.0377  6.8273   \n",
       "1             1  2010-01-05     0.9143  1.4402  1.7296  1.0371  6.8258   \n",
       "2             2  2010-01-06     0.9189  1.4404  1.7292  1.0333  6.8272   \n",
       "3             3  2010-01-07     0.9168  1.4314  1.7409  1.0351  6.8280   \n",
       "4             4  2010-01-08     0.9218  1.4357  1.7342  1.0345  6.8274   \n",
       "\n",
       "   Denmark  Hong Kong  India  Japan  Malaysia  \n",
       "0   5.1597     7.7555  46.27  92.55     3.396  \n",
       "1   5.1668     7.7564  46.13  91.48     3.385  \n",
       "2   5.1638     7.7546  45.72  92.53     3.379  \n",
       "3   5.1981     7.7539  45.67  93.31     3.368  \n",
       "4   5.1827     7.7553  45.50  92.70     3.375  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c86e1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    data.drop(\"Unnamed: 0.1\", axis=1, inplace=True)\n",
    "    data.rename(columns={\"Unnamed: 0\": \"Date\"}, inplace=True)\n",
    "    data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n",
    "    data.set_index(\"Date\", inplace=True)\n",
    "    data.replace(0, np.nan, inplace=True)\n",
    "    display(data)\n",
    "    print(\"Filling missing Values: \")\n",
    "    display(data.interpolate(method=\"linear\", limit_direction=\"forward\"))\n",
    "    data.interpolate(method=\"linear\", limit_direction=\"forward\", inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "747e0996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Australia</th>\n",
       "      <th>Europe</th>\n",
       "      <th>Brazil</th>\n",
       "      <th>Canada</th>\n",
       "      <th>China</th>\n",
       "      <th>Denmark</th>\n",
       "      <th>Hong Kong</th>\n",
       "      <th>India</th>\n",
       "      <th>Japan</th>\n",
       "      <th>Malaysia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>0.9133</td>\n",
       "      <td>1.4419</td>\n",
       "      <td>1.7200</td>\n",
       "      <td>1.0377</td>\n",
       "      <td>6.8273</td>\n",
       "      <td>5.1597</td>\n",
       "      <td>7.7555</td>\n",
       "      <td>46.27</td>\n",
       "      <td>92.55</td>\n",
       "      <td>3.3960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>0.9143</td>\n",
       "      <td>1.4402</td>\n",
       "      <td>1.7296</td>\n",
       "      <td>1.0371</td>\n",
       "      <td>6.8258</td>\n",
       "      <td>5.1668</td>\n",
       "      <td>7.7564</td>\n",
       "      <td>46.13</td>\n",
       "      <td>91.48</td>\n",
       "      <td>3.3850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>0.9189</td>\n",
       "      <td>1.4404</td>\n",
       "      <td>1.7292</td>\n",
       "      <td>1.0333</td>\n",
       "      <td>6.8272</td>\n",
       "      <td>5.1638</td>\n",
       "      <td>7.7546</td>\n",
       "      <td>45.72</td>\n",
       "      <td>92.53</td>\n",
       "      <td>3.3790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>0.9168</td>\n",
       "      <td>1.4314</td>\n",
       "      <td>1.7409</td>\n",
       "      <td>1.0351</td>\n",
       "      <td>6.8280</td>\n",
       "      <td>5.1981</td>\n",
       "      <td>7.7539</td>\n",
       "      <td>45.67</td>\n",
       "      <td>93.31</td>\n",
       "      <td>3.3680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>0.9218</td>\n",
       "      <td>1.4357</td>\n",
       "      <td>1.7342</td>\n",
       "      <td>1.0345</td>\n",
       "      <td>6.8274</td>\n",
       "      <td>5.1827</td>\n",
       "      <td>7.7553</td>\n",
       "      <td>45.50</td>\n",
       "      <td>92.70</td>\n",
       "      <td>3.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>0.6978</td>\n",
       "      <td>1.1174</td>\n",
       "      <td>4.0507</td>\n",
       "      <td>1.3073</td>\n",
       "      <td>6.9954</td>\n",
       "      <td>6.6829</td>\n",
       "      <td>7.7874</td>\n",
       "      <td>71.45</td>\n",
       "      <td>109.47</td>\n",
       "      <td>4.1260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>0.7004</td>\n",
       "      <td>1.1217</td>\n",
       "      <td>4.0152</td>\n",
       "      <td>1.3058</td>\n",
       "      <td>6.9864</td>\n",
       "      <td>6.6589</td>\n",
       "      <td>7.7857</td>\n",
       "      <td>71.30</td>\n",
       "      <td>108.85</td>\n",
       "      <td>4.1053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>0.7030</td>\n",
       "      <td>1.1227</td>\n",
       "      <td>4.0190</td>\n",
       "      <td>1.2962</td>\n",
       "      <td>6.9618</td>\n",
       "      <td>6.6554</td>\n",
       "      <td>7.7894</td>\n",
       "      <td>71.36</td>\n",
       "      <td>108.67</td>\n",
       "      <td>4.0918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3648 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Australia  Europe  Brazil  Canada   China  Denmark  Hong Kong  \\\n",
       "Date                                                                        \n",
       "2010-01-04     0.9133  1.4419  1.7200  1.0377  6.8273   5.1597     7.7555   \n",
       "2010-01-05     0.9143  1.4402  1.7296  1.0371  6.8258   5.1668     7.7564   \n",
       "2010-01-06     0.9189  1.4404  1.7292  1.0333  6.8272   5.1638     7.7546   \n",
       "2010-01-07     0.9168  1.4314  1.7409  1.0351  6.8280   5.1981     7.7539   \n",
       "2010-01-08     0.9218  1.4357  1.7342  1.0345  6.8274   5.1827     7.7553   \n",
       "...               ...     ...     ...     ...     ...      ...        ...   \n",
       "2019-12-27     0.6978  1.1174  4.0507  1.3073  6.9954   6.6829     7.7874   \n",
       "2019-12-28        NaN     NaN     NaN     NaN     NaN      NaN        NaN   \n",
       "2019-12-29        NaN     NaN     NaN     NaN     NaN      NaN        NaN   \n",
       "2019-12-30     0.7004  1.1217  4.0152  1.3058  6.9864   6.6589     7.7857   \n",
       "2019-12-31     0.7030  1.1227  4.0190  1.2962  6.9618   6.6554     7.7894   \n",
       "\n",
       "            India   Japan  Malaysia  \n",
       "Date                                 \n",
       "2010-01-04  46.27   92.55    3.3960  \n",
       "2010-01-05  46.13   91.48    3.3850  \n",
       "2010-01-06  45.72   92.53    3.3790  \n",
       "2010-01-07  45.67   93.31    3.3680  \n",
       "2010-01-08  45.50   92.70    3.3750  \n",
       "...           ...     ...       ...  \n",
       "2019-12-27  71.45  109.47    4.1260  \n",
       "2019-12-28    NaN     NaN       NaN  \n",
       "2019-12-29    NaN     NaN       NaN  \n",
       "2019-12-30  71.30  108.85    4.1053  \n",
       "2019-12-31  71.36  108.67    4.0918  \n",
       "\n",
       "[3648 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling missing Values: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Australia</th>\n",
       "      <th>Europe</th>\n",
       "      <th>Brazil</th>\n",
       "      <th>Canada</th>\n",
       "      <th>China</th>\n",
       "      <th>Denmark</th>\n",
       "      <th>Hong Kong</th>\n",
       "      <th>India</th>\n",
       "      <th>Japan</th>\n",
       "      <th>Malaysia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>0.913300</td>\n",
       "      <td>1.441900</td>\n",
       "      <td>1.720000</td>\n",
       "      <td>1.0377</td>\n",
       "      <td>6.8273</td>\n",
       "      <td>5.1597</td>\n",
       "      <td>7.755500</td>\n",
       "      <td>46.27</td>\n",
       "      <td>92.550000</td>\n",
       "      <td>3.3960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>0.914300</td>\n",
       "      <td>1.440200</td>\n",
       "      <td>1.729600</td>\n",
       "      <td>1.0371</td>\n",
       "      <td>6.8258</td>\n",
       "      <td>5.1668</td>\n",
       "      <td>7.756400</td>\n",
       "      <td>46.13</td>\n",
       "      <td>91.480000</td>\n",
       "      <td>3.3850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>0.918900</td>\n",
       "      <td>1.440400</td>\n",
       "      <td>1.729200</td>\n",
       "      <td>1.0333</td>\n",
       "      <td>6.8272</td>\n",
       "      <td>5.1638</td>\n",
       "      <td>7.754600</td>\n",
       "      <td>45.72</td>\n",
       "      <td>92.530000</td>\n",
       "      <td>3.3790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>0.916800</td>\n",
       "      <td>1.431400</td>\n",
       "      <td>1.740900</td>\n",
       "      <td>1.0351</td>\n",
       "      <td>6.8280</td>\n",
       "      <td>5.1981</td>\n",
       "      <td>7.753900</td>\n",
       "      <td>45.67</td>\n",
       "      <td>93.310000</td>\n",
       "      <td>3.3680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>0.921800</td>\n",
       "      <td>1.435700</td>\n",
       "      <td>1.734200</td>\n",
       "      <td>1.0345</td>\n",
       "      <td>6.8274</td>\n",
       "      <td>5.1827</td>\n",
       "      <td>7.755300</td>\n",
       "      <td>45.50</td>\n",
       "      <td>92.700000</td>\n",
       "      <td>3.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>0.697800</td>\n",
       "      <td>1.117400</td>\n",
       "      <td>4.050700</td>\n",
       "      <td>1.3073</td>\n",
       "      <td>6.9954</td>\n",
       "      <td>6.6829</td>\n",
       "      <td>7.787400</td>\n",
       "      <td>71.45</td>\n",
       "      <td>109.470000</td>\n",
       "      <td>4.1260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28</th>\n",
       "      <td>0.698667</td>\n",
       "      <td>1.118833</td>\n",
       "      <td>4.038867</td>\n",
       "      <td>1.3068</td>\n",
       "      <td>6.9924</td>\n",
       "      <td>6.6749</td>\n",
       "      <td>7.786833</td>\n",
       "      <td>71.40</td>\n",
       "      <td>109.263333</td>\n",
       "      <td>4.1191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29</th>\n",
       "      <td>0.699533</td>\n",
       "      <td>1.120267</td>\n",
       "      <td>4.027033</td>\n",
       "      <td>1.3063</td>\n",
       "      <td>6.9894</td>\n",
       "      <td>6.6669</td>\n",
       "      <td>7.786267</td>\n",
       "      <td>71.35</td>\n",
       "      <td>109.056667</td>\n",
       "      <td>4.1122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>0.700400</td>\n",
       "      <td>1.121700</td>\n",
       "      <td>4.015200</td>\n",
       "      <td>1.3058</td>\n",
       "      <td>6.9864</td>\n",
       "      <td>6.6589</td>\n",
       "      <td>7.785700</td>\n",
       "      <td>71.30</td>\n",
       "      <td>108.850000</td>\n",
       "      <td>4.1053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>0.703000</td>\n",
       "      <td>1.122700</td>\n",
       "      <td>4.019000</td>\n",
       "      <td>1.2962</td>\n",
       "      <td>6.9618</td>\n",
       "      <td>6.6554</td>\n",
       "      <td>7.789400</td>\n",
       "      <td>71.36</td>\n",
       "      <td>108.670000</td>\n",
       "      <td>4.0918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3648 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Australia    Europe    Brazil  Canada   China  Denmark  Hong Kong  \\\n",
       "Date                                                                            \n",
       "2010-01-04   0.913300  1.441900  1.720000  1.0377  6.8273   5.1597   7.755500   \n",
       "2010-01-05   0.914300  1.440200  1.729600  1.0371  6.8258   5.1668   7.756400   \n",
       "2010-01-06   0.918900  1.440400  1.729200  1.0333  6.8272   5.1638   7.754600   \n",
       "2010-01-07   0.916800  1.431400  1.740900  1.0351  6.8280   5.1981   7.753900   \n",
       "2010-01-08   0.921800  1.435700  1.734200  1.0345  6.8274   5.1827   7.755300   \n",
       "...               ...       ...       ...     ...     ...      ...        ...   \n",
       "2019-12-27   0.697800  1.117400  4.050700  1.3073  6.9954   6.6829   7.787400   \n",
       "2019-12-28   0.698667  1.118833  4.038867  1.3068  6.9924   6.6749   7.786833   \n",
       "2019-12-29   0.699533  1.120267  4.027033  1.3063  6.9894   6.6669   7.786267   \n",
       "2019-12-30   0.700400  1.121700  4.015200  1.3058  6.9864   6.6589   7.785700   \n",
       "2019-12-31   0.703000  1.122700  4.019000  1.2962  6.9618   6.6554   7.789400   \n",
       "\n",
       "            India       Japan  Malaysia  \n",
       "Date                                     \n",
       "2010-01-04  46.27   92.550000    3.3960  \n",
       "2010-01-05  46.13   91.480000    3.3850  \n",
       "2010-01-06  45.72   92.530000    3.3790  \n",
       "2010-01-07  45.67   93.310000    3.3680  \n",
       "2010-01-08  45.50   92.700000    3.3750  \n",
       "...           ...         ...       ...  \n",
       "2019-12-27  71.45  109.470000    4.1260  \n",
       "2019-12-28  71.40  109.263333    4.1191  \n",
       "2019-12-29  71.35  109.056667    4.1122  \n",
       "2019-12-30  71.30  108.850000    4.1053  \n",
       "2019-12-31  71.36  108.670000    4.0918  \n",
       "\n",
       "[3648 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = preprocess(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d22daf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOK_BACK = 30\n",
    "PREDICT_DAY = 1\n",
    "SPLIT_RATIO = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d8191f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Data(\n",
    "    data, lookback=LOOK_BACK, pred_len=PREDICT_DAY, split_ratio=SPLIT_RATIO\n",
    "):\n",
    "    if lookback < 2:\n",
    "        print(\"ERROR: Lookback too small\")\n",
    "        return -1\n",
    "\n",
    "    # declarations\n",
    "\n",
    "    x = {}\n",
    "    y = {}\n",
    "    xtr = {}\n",
    "    xt = {}\n",
    "    ytr = {}\n",
    "    yt = {}\n",
    "    scalers = {}\n",
    "\n",
    "    # Creating stepped data\n",
    "\n",
    "    for i in data.columns:\n",
    "        xtemp = pd.DataFrame(data[i])\n",
    "        for j in range(1, lookback + 1):\n",
    "            xtemp[i + str(j)] = data[i].shift(-1 * j)\n",
    "        x[i] = xtemp.dropna()\n",
    "\n",
    "    # Splitting data into x and y\n",
    "\n",
    "    for i in x.keys():\n",
    "        y[i] = pd.DataFrame(x[i].iloc[:, -pred_len])\n",
    "        x[i] = x[i].iloc[:, :-pred_len]\n",
    "\n",
    "    # Normalizing x and y values\n",
    "\n",
    "    for i in x.keys():\n",
    "        scalers[i + \"_x\"] = MinMaxScaler(feature_range=(0, 1))\n",
    "        x[i] = scalers[i + \"_x\"].fit_transform(x[i])\n",
    "        scalers[i + \"_y\"] = MinMaxScaler(feature_range=(0, 1))\n",
    "        y[i] = scalers[i + \"_y\"].fit_transform(y[i])\n",
    "\n",
    "    # setting train and test sizes\n",
    "\n",
    "    tr_len = int(split_ratio * y[\"India\"].shape[0])\n",
    "    t_len = y[\"India\"].shape[0] - tr_len\n",
    "\n",
    "    # creating training and testing data\n",
    "\n",
    "    for i in x.keys():\n",
    "        xtr[i] = x[i][:tr_len]\n",
    "        ytr[i] = y[i][:tr_len]\n",
    "        xt[i] = x[i][-t_len:]\n",
    "        yt[i] = y[i][-t_len:]\n",
    "\n",
    "    # returning pertinent data\n",
    "\n",
    "    return x, y, xtr, xt, ytr, yt, scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4dff5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, xtr, xt, ytr, yt, scalers = Create_Data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b99ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(sequence_length, feature_dim, num_transformer_blocks=3):\n",
    "    inputs = Input(shape=(sequence_length, feature_dim))\n",
    "    x = inputs\n",
    "\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        # Transformer Block with multi-head attention\n",
    "        query = LayerNormalization(epsilon=1e-6)(x)\n",
    "        key = LayerNormalization(epsilon=1e-6)(x)\n",
    "        value = LayerNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "        attn_output = MultiHeadAttention(num_heads=4, key_dim=feature_dim, dropout=0.3)(\n",
    "            query, value, key=key\n",
    "        )\n",
    "        x = Add()([x, attn_output])  # Residual connection\n",
    "        x = LayerNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "        # Feed Forward Network inside transformer\n",
    "        ffn_output = Dense(128, activation=\"relu\")(x)\n",
    "        ffn_output = Dropout(0.3)(ffn_output)\n",
    "        ffn_output = Dense(64, activation=\"relu\")(ffn_output)\n",
    "        ffn_output = Dense(feature_dim)(ffn_output)\n",
    "        x = Add()([x, ffn_output])  # Residual connection\n",
    "        x = LayerNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(32, activation=\"relu\")(x)\n",
    "    outputs = Dense(PREDICT_DAY)(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def Create_model(x, y, lookback=LOOK_BACK, Pred_size=PREDICT_DAY):\n",
    "    models = {}\n",
    "    for i in x.keys():\n",
    "        reshaped_x = np.reshape(x[i], (x[i].shape[0], 1, x[i].shape[1]))\n",
    "        models[i] = transformer_encoder(1, reshaped_x.shape[2])\n",
    "        print(i)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c91c0503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Australia\n",
      "Europe\n",
      "Brazil\n",
      "Canada\n",
      "China\n",
      "Denmark\n",
      "Hong Kong\n",
      "India\n",
      "Japan\n",
      "Malaysia\n"
     ]
    }
   ],
   "source": [
    "m = Create_model(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84e10c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Execute_model(model, xtr, ytr, xt, yt, scaler):\n",
    "    MAPE = {}\n",
    "    MAE = {}\n",
    "    MSE = {}\n",
    "    MSE_Actual = {}\n",
    "    MAE_Actual = {}\n",
    "    MAPE_Actual = {}\n",
    "    for i in model.keys():\n",
    "        print(i)\n",
    "        reshaped_xtr = np.reshape(xtr[i], (xtr[i].shape[0], 1, xtr[i].shape[1]))\n",
    "        reshaped_xt = np.reshape(xt[i], (xt[i].shape[0], 1, xt[i].shape[1]))\n",
    "\n",
    "        es = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=10)\n",
    "        reduce_lr = ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\", factor=0.2, patience=5, min_lr=0.0001\n",
    "        )\n",
    "\n",
    "        model[i].fit(\n",
    "            reshaped_xtr,\n",
    "            ytr[i],\n",
    "            epochs=100,\n",
    "            batch_size=64,\n",
    "            verbose=1,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[es, reduce_lr],\n",
    "        )\n",
    "\n",
    "        temp = model[i].predict(reshaped_xt)\n",
    "        pred = scaler[i + \"_y\"].inverse_transform(temp)\n",
    "        act = scaler[i + \"_y\"].inverse_transform(yt[i])\n",
    "\n",
    "        MSE[i] = mean_squared_error(yt[i], temp)\n",
    "        MAE[i] = mean_absolute_error(yt[i], temp)\n",
    "        MAPE[i] = mean_absolute_percentage_error(yt[i], temp)\n",
    "        \n",
    "        MSE_Actual[i] = mean_squared_error(act, pred)\n",
    "        MAE_Actual[i] = mean_absolute_error(act, pred)\n",
    "        MAPE_Actual[i] = mean_absolute_percentage_error(act, pred)\n",
    "        \n",
    "    # Tabulating Data\n",
    "    \n",
    "    metric = pd.DataFrame([MSE, MAE, MAPE])\n",
    "    metric[\"Metric\"] = [\"MSE\", \"MAE\", \"MAPE\"]\n",
    "    metric.set_index(\"Metric\", inplace=True)\n",
    "    \n",
    "    results = pd.DataFrame([MSE_Actual, MAE_Actual, MAPE_Actual])\n",
    "    results[\"Metric\"] = [\"MSE\", \"MAE\", \"MAPE\"]\n",
    "    results.set_index(\"Metric\", inplace=True)\n",
    "    \n",
    "    return metric, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9e0a822",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Australia\n",
      "Epoch 1/100\n",
      "37/37 [==============================] - 6s 21ms/step - loss: 0.1509 - val_loss: 0.0104 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0976 - val_loss: 0.0198 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0840 - val_loss: 0.0242 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0832 - val_loss: 0.0201 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0783 - val_loss: 0.0195 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0770 - val_loss: 0.0128 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0786 - val_loss: 0.0235 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0752 - val_loss: 0.0207 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0762 - val_loss: 0.0216 - lr: 2.0000e-04\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0742 - val_loss: 0.0258 - lr: 2.0000e-04\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0740 - val_loss: 0.0222 - lr: 2.0000e-04\n",
      "Epoch 11: early stopping\n",
      "23/23 [==============================] - 0s 2ms/step\n",
      "Europe\n",
      "Epoch 1/100\n",
      "37/37 [==============================] - 6s 20ms/step - loss: 0.1549 - val_loss: 0.0192 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0802 - val_loss: 0.0268 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0747 - val_loss: 0.0406 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0692 - val_loss: 0.0394 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0640 - val_loss: 0.0489 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0629 - val_loss: 0.0498 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0614 - val_loss: 0.0556 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0613 - val_loss: 0.0545 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0599 - val_loss: 0.0556 - lr: 2.0000e-04\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0595 - val_loss: 0.0568 - lr: 2.0000e-04\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0586 - val_loss: 0.0566 - lr: 2.0000e-04\n",
      "Epoch 11: early stopping\n",
      "23/23 [==============================] - 1s 3ms/step\n",
      "Brazil\n",
      "Epoch 1/100\n",
      "37/37 [==============================] - 8s 27ms/step - loss: 0.2129 - val_loss: 0.1461 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0844 - val_loss: 0.1902 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0800 - val_loss: 0.1860 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0751 - val_loss: 0.1880 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0732 - val_loss: 0.1687 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0711 - val_loss: 0.1904 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0701 - val_loss: 0.1908 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0697 - val_loss: 0.1892 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0684 - val_loss: 0.1912 - lr: 2.0000e-04\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0697 - val_loss: 0.1884 - lr: 2.0000e-04\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0698 - val_loss: 0.1848 - lr: 2.0000e-04\n",
      "Epoch 11: early stopping\n",
      "23/23 [==============================] - 1s 3ms/step\n",
      "Canada\n",
      "Epoch 1/100\n",
      "37/37 [==============================] - 8s 25ms/step - loss: 0.0934 - val_loss: 0.3221 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 0.0608 - val_loss: 0.3045 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0608 - val_loss: 0.2825 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0598 - val_loss: 0.2765 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0592 - val_loss: 0.2757 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0565 - val_loss: 0.2543 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0557 - val_loss: 0.2265 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0551 - val_loss: 0.2237 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0553 - val_loss: 0.2482 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0543 - val_loss: 0.2423 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0541 - val_loss: 0.2156 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0538 - val_loss: 0.2151 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0537 - val_loss: 0.2148 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0528 - val_loss: 0.2107 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0534 - val_loss: 0.2097 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0534 - val_loss: 0.2225 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0536 - val_loss: 0.2229 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0523 - val_loss: 0.2055 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0533 - val_loss: 0.2095 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0526 - val_loss: 0.2031 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0525 - val_loss: 0.2105 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0525 - val_loss: 0.2004 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0519 - val_loss: 0.1948 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0531 - val_loss: 0.2015 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0519 - val_loss: 0.2055 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0521 - val_loss: 0.2011 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0508 - val_loss: 0.2010 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0524 - val_loss: 0.2068 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0514 - val_loss: 0.2008 - lr: 2.0000e-04\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0508 - val_loss: 0.2024 - lr: 2.0000e-04\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0510 - val_loss: 0.2015 - lr: 2.0000e-04\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0509 - val_loss: 0.1986 - lr: 2.0000e-04\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0521 - val_loss: 0.2001 - lr: 2.0000e-04\n",
      "Epoch 33: early stopping\n",
      "23/23 [==============================] - 1s 3ms/step\n",
      "China\n",
      "Epoch 1/100\n",
      "37/37 [==============================] - 7s 24ms/step - loss: 0.1398 - val_loss: 0.2652 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 0.0592 - val_loss: 0.2661 - lr: 0.0010\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0497 - val_loss: 0.2465 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0440 - val_loss: 0.2205 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0428 - val_loss: 0.2075 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0406 - val_loss: 0.1905 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0394 - val_loss: 0.1794 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0389 - val_loss: 0.1715 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0389 - val_loss: 0.1594 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0376 - val_loss: 0.1654 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0370 - val_loss: 0.1511 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0372 - val_loss: 0.1479 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0378 - val_loss: 0.1382 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0367 - val_loss: 0.1321 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0365 - val_loss: 0.1363 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0366 - val_loss: 0.1349 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0362 - val_loss: 0.1334 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0359 - val_loss: 0.1353 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0360 - val_loss: 0.1192 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0359 - val_loss: 0.1255 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0358 - val_loss: 0.1320 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0362 - val_loss: 0.1290 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0358 - val_loss: 0.1134 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0358 - val_loss: 0.1287 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0360 - val_loss: 0.1168 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0359 - val_loss: 0.1222 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0359 - val_loss: 0.1278 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0357 - val_loss: 0.1307 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0357 - val_loss: 0.1255 - lr: 2.0000e-04\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0356 - val_loss: 0.1251 - lr: 2.0000e-04\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0357 - val_loss: 0.1251 - lr: 2.0000e-04\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0357 - val_loss: 0.1274 - lr: 2.0000e-04\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0357 - val_loss: 0.1235 - lr: 2.0000e-04\n",
      "Epoch 33: early stopping\n",
      "23/23 [==============================] - 1s 3ms/step\n",
      "Denmark\n",
      "Epoch 1/100\n",
      "37/37 [==============================] - 7s 22ms/step - loss: 0.1802 - val_loss: 0.2805 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 0.0802 - val_loss: 0.3075 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 0.0707 - val_loss: 0.3221 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0673 - val_loss: 0.2711 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0640 - val_loss: 0.2880 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0620 - val_loss: 0.2990 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0606 - val_loss: 0.2558 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0602 - val_loss: 0.2591 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0602 - val_loss: 0.2512 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0595 - val_loss: 0.2563 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0588 - val_loss: 0.2489 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0598 - val_loss: 0.2488 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0590 - val_loss: 0.2481 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0573 - val_loss: 0.2358 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0583 - val_loss: 0.2196 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0569 - val_loss: 0.2244 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0564 - val_loss: 0.2181 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0576 - val_loss: 0.2113 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0569 - val_loss: 0.2057 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0565 - val_loss: 0.2049 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0570 - val_loss: 0.2138 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0562 - val_loss: 0.2023 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0567 - val_loss: 0.1929 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0569 - val_loss: 0.1993 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0573 - val_loss: 0.1990 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0562 - val_loss: 0.1924 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0568 - val_loss: 0.1930 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0562 - val_loss: 0.1901 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0562 - val_loss: 0.1910 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0560 - val_loss: 0.1872 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0567 - val_loss: 0.1739 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0561 - val_loss: 0.1833 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0557 - val_loss: 0.1863 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0557 - val_loss: 0.1754 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0563 - val_loss: 0.1748 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0561 - val_loss: 0.1764 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0562 - val_loss: 0.1760 - lr: 2.0000e-04\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0561 - val_loss: 0.1753 - lr: 2.0000e-04\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0551 - val_loss: 0.1763 - lr: 2.0000e-04\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0556 - val_loss: 0.1748 - lr: 2.0000e-04\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0556 - val_loss: 0.1751 - lr: 2.0000e-04\n",
      "Epoch 41: early stopping\n",
      "23/23 [==============================] - 1s 3ms/step\n",
      "Hong Kong\n",
      "Epoch 1/100\n",
      "37/37 [==============================] - 7s 28ms/step - loss: 0.1030 - val_loss: 0.1093 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0311 - val_loss: 0.1150 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0255 - val_loss: 0.1196 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0232 - val_loss: 0.1236 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0215 - val_loss: 0.1139 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0209 - val_loss: 0.1146 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0200 - val_loss: 0.1137 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0198 - val_loss: 0.1143 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0198 - val_loss: 0.1147 - lr: 2.0000e-04\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0201 - val_loss: 0.1142 - lr: 2.0000e-04\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0201 - val_loss: 0.1135 - lr: 2.0000e-04\n",
      "Epoch 11: early stopping\n",
      "23/23 [==============================] - 1s 3ms/step\n",
      "India\n",
      "Epoch 1/100\n",
      "37/37 [==============================] - 7s 23ms/step - loss: 0.1448 - val_loss: 0.2722 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 0.0804 - val_loss: 0.2673 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 0.0759 - val_loss: 0.2335 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0730 - val_loss: 0.2305 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0715 - val_loss: 0.2523 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0703 - val_loss: 0.2170 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0685 - val_loss: 0.2216 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0670 - val_loss: 0.1882 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0675 - val_loss: 0.1914 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0670 - val_loss: 0.1980 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0672 - val_loss: 0.1687 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0655 - val_loss: 0.1879 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0647 - val_loss: 0.1645 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0653 - val_loss: 0.1694 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0652 - val_loss: 0.1691 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0651 - val_loss: 0.1522 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0644 - val_loss: 0.1535 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0644 - val_loss: 0.1444 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0639 - val_loss: 0.1482 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0646 - val_loss: 0.1500 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0642 - val_loss: 0.1357 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0646 - val_loss: 0.1546 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0640 - val_loss: 0.1538 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0640 - val_loss: 0.1441 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0636 - val_loss: 0.1303 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0637 - val_loss: 0.1313 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0643 - val_loss: 0.1461 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0635 - val_loss: 0.1429 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0637 - val_loss: 0.1317 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0641 - val_loss: 0.1333 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0630 - val_loss: 0.1330 - lr: 2.0000e-04\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0628 - val_loss: 0.1337 - lr: 2.0000e-04\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0638 - val_loss: 0.1362 - lr: 2.0000e-04\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0631 - val_loss: 0.1327 - lr: 2.0000e-04\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0638 - val_loss: 0.1327 - lr: 2.0000e-04\n",
      "Epoch 35: early stopping\n",
      "23/23 [==============================] - 1s 3ms/step\n",
      "Japan\n",
      "Epoch 1/100\n",
      "37/37 [==============================] - 7s 22ms/step - loss: 0.2105 - val_loss: 0.2171 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1285 - val_loss: 0.2386 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 0.1133 - val_loss: 0.1848 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.1083 - val_loss: 0.2155 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.1067 - val_loss: 0.1976 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.1054 - val_loss: 0.1740 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.1045 - val_loss: 0.1493 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.1016 - val_loss: 0.1465 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.1028 - val_loss: 0.1524 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.1005 - val_loss: 0.1509 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.1004 - val_loss: 0.1331 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0995 - val_loss: 0.1478 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.1004 - val_loss: 0.1330 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0991 - val_loss: 0.1366 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0979 - val_loss: 0.1351 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0981 - val_loss: 0.1254 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0996 - val_loss: 0.1167 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0974 - val_loss: 0.1242 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0980 - val_loss: 0.1056 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0983 - val_loss: 0.1130 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0972 - val_loss: 0.1029 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0966 - val_loss: 0.0991 - lr: 0.0010\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0967 - val_loss: 0.1181 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0978 - val_loss: 0.0977 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0978 - val_loss: 0.0969 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0965 - val_loss: 0.1001 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0970 - val_loss: 0.0931 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0975 - val_loss: 0.0920 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0973 - val_loss: 0.1021 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0963 - val_loss: 0.0952 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0975 - val_loss: 0.0987 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0965 - val_loss: 0.0964 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0968 - val_loss: 0.0917 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0968 - val_loss: 0.1006 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0965 - val_loss: 0.1006 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0975 - val_loss: 0.0986 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0966 - val_loss: 0.0917 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0965 - val_loss: 0.0805 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0965 - val_loss: 0.0880 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0969 - val_loss: 0.0895 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0966 - val_loss: 0.0945 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0957 - val_loss: 0.0910 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0967 - val_loss: 0.0908 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0959 - val_loss: 0.0926 - lr: 2.0000e-04\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0955 - val_loss: 0.0913 - lr: 2.0000e-04\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0959 - val_loss: 0.0936 - lr: 2.0000e-04\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0967 - val_loss: 0.0916 - lr: 2.0000e-04\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0960 - val_loss: 0.0919 - lr: 2.0000e-04\n",
      "Epoch 48: early stopping\n",
      "23/23 [==============================] - 1s 3ms/step\n",
      "Malaysia\n",
      "Epoch 1/100\n",
      "37/37 [==============================] - 7s 25ms/step - loss: 0.1306 - val_loss: 0.5469 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 0.0744 - val_loss: 0.5547 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0660 - val_loss: 0.5338 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0645 - val_loss: 0.4960 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0594 - val_loss: 0.5159 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0587 - val_loss: 0.4748 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0583 - val_loss: 0.4771 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0592 - val_loss: 0.4620 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0590 - val_loss: 0.4702 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0586 - val_loss: 0.4451 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0568 - val_loss: 0.4196 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0569 - val_loss: 0.4227 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0566 - val_loss: 0.4528 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0575 - val_loss: 0.4427 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0567 - val_loss: 0.4390 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0569 - val_loss: 0.4283 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0552 - val_loss: 0.4175 - lr: 2.0000e-04\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0559 - val_loss: 0.4135 - lr: 2.0000e-04\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0552 - val_loss: 0.4137 - lr: 2.0000e-04\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0548 - val_loss: 0.4128 - lr: 2.0000e-04\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0547 - val_loss: 0.4194 - lr: 2.0000e-04\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0546 - val_loss: 0.4163 - lr: 2.0000e-04\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0548 - val_loss: 0.4194 - lr: 2.0000e-04\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0549 - val_loss: 0.4169 - lr: 2.0000e-04\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0549 - val_loss: 0.4165 - lr: 2.0000e-04\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0561 - val_loss: 0.4190 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0551 - val_loss: 0.4194 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0550 - val_loss: 0.4159 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0554 - val_loss: 0.4177 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0545 - val_loss: 0.4182 - lr: 1.0000e-04\n",
      "Epoch 30: early stopping\n",
      "23/23 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "metric, result = Execute_model(m, xtr, ytr, xt, yt, scalers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "256b816d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Australia</th>\n",
       "      <th>Europe</th>\n",
       "      <th>Brazil</th>\n",
       "      <th>Canada</th>\n",
       "      <th>China</th>\n",
       "      <th>Denmark</th>\n",
       "      <th>Hong Kong</th>\n",
       "      <th>India</th>\n",
       "      <th>Japan</th>\n",
       "      <th>Malaysia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.011162</td>\n",
       "      <td>0.005668</td>\n",
       "      <td>3.053410</td>\n",
       "      <td>0.054169</td>\n",
       "      <td>0.225636</td>\n",
       "      <td>0.536855</td>\n",
       "      <td>0.006486</td>\n",
       "      <td>212.827525</td>\n",
       "      <td>207.384275</td>\n",
       "      <td>0.672281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.099817</td>\n",
       "      <td>0.067832</td>\n",
       "      <td>1.726347</td>\n",
       "      <td>0.230234</td>\n",
       "      <td>0.413969</td>\n",
       "      <td>0.696002</td>\n",
       "      <td>0.079232</td>\n",
       "      <td>14.359100</td>\n",
       "      <td>14.249336</td>\n",
       "      <td>0.812620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>0.140835</td>\n",
       "      <td>0.059992</td>\n",
       "      <td>0.451010</td>\n",
       "      <td>0.175268</td>\n",
       "      <td>0.059964</td>\n",
       "      <td>0.105982</td>\n",
       "      <td>0.010108</td>\n",
       "      <td>0.205663</td>\n",
       "      <td>0.129639</td>\n",
       "      <td>0.198361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Australia    Europe    Brazil    Canada     China   Denmark  \\\n",
       "Metric                                                                \n",
       "MSE      0.011162  0.005668  3.053410  0.054169  0.225636  0.536855   \n",
       "MAE      0.099817  0.067832  1.726347  0.230234  0.413969  0.696002   \n",
       "MAPE     0.140835  0.059992  0.451010  0.175268  0.059964  0.105982   \n",
       "\n",
       "        Hong Kong       India       Japan  Malaysia  \n",
       "Metric                                               \n",
       "MSE      0.006486  212.827525  207.384275  0.672281  \n",
       "MAE      0.079232   14.359100   14.249336  0.812620  \n",
       "MAPE     0.010108    0.205663    0.129639  0.198361  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00bc2ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Australia</th>\n",
       "      <th>Europe</th>\n",
       "      <th>Brazil</th>\n",
       "      <th>Canada</th>\n",
       "      <th>China</th>\n",
       "      <th>Denmark</th>\n",
       "      <th>Hong Kong</th>\n",
       "      <th>India</th>\n",
       "      <th>Japan</th>\n",
       "      <th>Malaysia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>5.959041e-02</td>\n",
       "      <td>0.027988</td>\n",
       "      <td>0.412136</td>\n",
       "      <td>0.204716</td>\n",
       "      <td>0.174108</td>\n",
       "      <td>0.115913</td>\n",
       "      <td>0.640932</td>\n",
       "      <td>0.229839</td>\n",
       "      <td>0.083420</td>\n",
       "      <td>0.276604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>2.306300e-01</td>\n",
       "      <td>0.150738</td>\n",
       "      <td>0.634243</td>\n",
       "      <td>0.447577</td>\n",
       "      <td>0.363641</td>\n",
       "      <td>0.323406</td>\n",
       "      <td>0.787598</td>\n",
       "      <td>0.471873</td>\n",
       "      <td>0.285787</td>\n",
       "      <td>0.521244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>1.981143e+12</td>\n",
       "      <td>0.776082</td>\n",
       "      <td>0.758248</td>\n",
       "      <td>0.626467</td>\n",
       "      <td>0.504829</td>\n",
       "      <td>0.453789</td>\n",
       "      <td>0.908359</td>\n",
       "      <td>0.557128</td>\n",
       "      <td>0.417781</td>\n",
       "      <td>0.704402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Australia    Europe    Brazil    Canada     China   Denmark  \\\n",
       "Metric                                                                   \n",
       "MSE     5.959041e-02  0.027988  0.412136  0.204716  0.174108  0.115913   \n",
       "MAE     2.306300e-01  0.150738  0.634243  0.447577  0.363641  0.323406   \n",
       "MAPE    1.981143e+12  0.776082  0.758248  0.626467  0.504829  0.453789   \n",
       "\n",
       "        Hong Kong     India     Japan  Malaysia  \n",
       "Metric                                           \n",
       "MSE      0.640932  0.229839  0.083420  0.276604  \n",
       "MAE      0.787598  0.471873  0.285787  0.521244  \n",
       "MAPE     0.908359  0.557128  0.417781  0.704402  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c97fc57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Define the filename\n",
    "filename = \"./results.json\"\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.isfile(filename):\n",
    "    # If the file exists, load the existing data\n",
    "    with open(filename, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "else:\n",
    "    # If the file doesn't exist, create an empty dictionary\n",
    "    data = {}\n",
    "\n",
    "# Add the result to the dictionary\n",
    "data[\"Transformer\"] = metric.to_dict()\n",
    "\n",
    "# Write the dictionary to the file\n",
    "with open(filename, \"w\") as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45fc3cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
